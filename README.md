# Pipeline m√©t√©o ‚Äì Semaine du Num√©rique

> Collecter, transformer et exposer les bulletins m√©t√©o de la Direction G√©n√©rale de la M√©t√©orologie (Burkina Faso).

---

## 1. Architecture g√©n√©rale

![Scraping](assets/scrapping.png)

| Bloc                  | Description                                                                                                      |
|----------------------|------------------------------------------------------------------------------------------------------------------|
| `meteo_scraper.py`   | Explore les pages `https://meteoburkina.bf/produits/bulletin-quotidien/`, d√©tecte les liens PDF valides, t√©l√©charge dans `bulletins_pdf/`. |
| `pdf_to_images_recursive.py` | Convertit l‚Äôint√©gralit√© des PDF (`2024/<MOIS>/...pdf`) en PNG haute r√©solution (`2024_fullpage/`).                             |
| `crop_maps_recursive.py`     | D√©coupe automatiquement les cartes observ√©es/pr√©vues dans chaque page et range le r√©sultat dans `2024_maps/<MOIS>/`.             |
| `extract_temps_qwen.py`      | Lisent les cartes (via Qwen3-VL + Ollama) pour extraire Tmin/Tmax/ic√¥nes sur toutes les villes r√©f√©renc√©es dans `cities_rel.json`. |
| `merge_maps.py`      | Fusionne `*_map1_observed.json` et `*_map2_forecast.json` en un fichier unique `*_merged.json` en ajoutant lat/lon. |
| `merge_all_merged.py`| Agr√®ge tous les `*_merged.json` en `data/all_merged.json` (copie √©galement sous `2024_temps_merged/all_merged.json`). |
| `evaluate_forecasts.py` | Calcule MAE/RMSE et accuracy macro-F1 puis √©crit `data/evaluation_metrics.json`.                                     |
| FastAPI (`app/`)     | API REST + base SQLite (`data/meteo.db`) : import des bulletins, CRUD stations, export de `all_merged.json`, statistiques, d√©clenchement du pipeline (`/scraping/start`). |
| Frontend React (`frontend/frontend`) | Dashboard (Cartes + KPIs), Files (aper√ßu des bulletins), Stations (Tmin/Tmax), √âvaluation, Logs, Param√®tres.  |

---

## 2. Mise en route rapide

### Pr√©requis

- Python ‚â• 3.10 (virtualenv recommand√©)
- Node.js ‚â• 18 (pour le dashboard)
- D√©pendances syst√®me : `tesseract-ocr`, `libgl1`, `libglib2.0-0`, `poppler-utils`
- (Optionnel) Ollama + mod√®le `qwen3-vl:8b` si vous utilisez `extract_temps_qwen.py`

### Installation backend

```bash
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt  # si disponible, sinon installez les libs list√©es dans les scripts
```

### Installation frontend

```bash
cd frontend/frontend
npm install
```

### Lancer l‚ÄôAPI

```bash
uvicorn app.main:app --reload
```

Au d√©marrage, l‚ÄôAPI :
1. cr√©e `data/meteo.db` si n√©cessaire ;
2. importe automatiquement les donn√©es de `data/all_merged.json` (seed) si aucune entr√©e n‚Äôest pr√©sente ;
3. expose les routes (bulletins, stations, stats, exports, scraping, etc.).

### Lancer le dashboard

```bash
cd frontend/frontend
REACT_APP_API_URL=http://localhost:8000 npm start
```

Les pages se rafra√Æchissent automatiquement en interrogeant l‚ÄôAPI FastAPI.

---

## 3. Pipeline d√©taill√©

> Tout ce qui suit peut √™tre orchestr√© via `python automate_pipeline.py --api-url http://127.0.0.1:8000`.

### √âtape 1 ‚Äì Scraping

1. `python meteo_scraper.py`
   - Parcourt les pages list√©es (`?page=1,2...`).
   - V√©rifie chaque lien avec une expression r√©guli√®re stricte.
   - T√©l√©charge les PDF non pr√©sents dans `bulletins_pdf/`.

### √âtape 2 ‚Äì Conversion PDF ‚Üí images

```bash
python pdf_to_images_recursive.py
```

- Convertit tous les PDF trouv√©s dans `2024/` vers `2024_fullpage/<MOIS>/...png`.
- DPI configurable dans le script (`dpi=200` par d√©faut).

### √âtape 3 ‚Äì D√©coupe des cartes & g√©or√©f√©rencement

- Avant de lancer les extractions, utilisez `annotate_cities.py` pour cliquer chaque ville sur la carte de r√©f√©rence (`base_map_cities.png`). Le script produit `cities_positions.json`, base des coordonn√©es relatives.

![Annotate cities](assets/coordonner.png)

```bash
python crop_maps_recursive.py
```

- Utilise les coordonn√©es relatives (`MAP1_X0`, etc.) pour extraire automatiquement `map1` (observ√©) et `map2` (pr√©vision).
- R√©sultat sous `2024_maps/<MOIS>/..._map{1,2}.png`.

### √âtape 4 ‚Äì Extraction des temp√©ratures/ic√¥nes

![Extraction Qwen](assets/qwen3_data_extract.png)

Deux options :

1. **OCR Tesseract (`extract_temps_relative.py`)**
   - Crops autour des coordonn√©es (`cities_rel.json`) et utilise pytesseract.
   - Produit `2024_temps_json_rel/<MOIS>/..._observed.json`.

2. **LLM (`extract_temps_qwen.py`)**
   - Envoie les crops √† Qwen3-VL (Ollama) pour lire Tmin/Tmax + ic√¥nes.
   - √âcrit `2024_temps_qwen/<MOIS>/..._map1_observed.json` & `..._map2_forecast.json`.

### √âtape 5 ‚Äì Fusion

```bash
python merge_maps.py
```

- Fusionne observed/pr√©vision en `2024_temps_merged/<MOIS>/..._merged.json`.
- Chaque entr√©e contient :
  ```json
  {
    "nom": "BANFORA",
    "latitude": 10.6333,
    "longitude": -4.7667,
    "Tmin_obs": 24,
    "Tmax_obs": 31,
    "temps_obs": "nuageux",
    "Tmin_prev": 23,
    "Tmax_prev": 29,
    "temps_prev": "pluie",
    "interpretation_moore": "",
    "interpretation_dioula": ""
  }
  ```

### √âtape 6 ‚Äì Agr√©gation & m√©triques

```bash
python merge_all_merged.py          # cr√©e 2024_temps_merged/all_merged.json et data/all_merged.json
python evaluate_forecasts.py        # lit data/all_merged.json, √©crit data/evaluation_metrics.json
```

`evaluate_forecasts` calcule MAE/RMSE pour Tmin/Tmax et accuracy/F1 macro pour les ic√¥nes.

---

## 4. API FastAPI

| Endpoint                         | Description                                                                                                    |
|---------------------------------|----------------------------------------------------------------------------------------------------------------|
| `GET /health`                   | Ping simple.                                                                                                   |
| `GET /stats/overview`           | Nombre de bulletins/stations/reports + dernier bulletin.                                                       |
| `GET /bulletins`                | Liste pagin√©e des bulletins (`start_date`, `end_date`, `limit`, `offset`).                                     |
| `GET /bulletins/{id}`           | D√©tail d‚Äôun bulletin (stations, Tmin/Tmax).                                                                    |
| `POST /bulletins/import`        | Import d‚Äôun JSON `*_merged.json` (supporte `replace_existing`).                                                |
| `DELETE /bulletins/{id}`        | Supprime un bulletin (cascade sur les `station_reports`).                                                      |
| `GET /stations`                 | Annuaire des stations + dernier `Tmin/Tmax` observ√©/pr√©vu.                                                      |
| `GET /stations/{id}`            | D√©tail d‚Äôune station (metadata + dernier relev√©).                                                              |
| `GET /stations/{id}/reports`    | Historique des reports pour la station.                                                                        |
| `GET /exports/all-merged`       | Renvoie `data/all_merged.json`.                                                                                |
| `GET /exports/merged-file?path=`| Renvoie le contenu JSON du fichier `2024_temps_merged/<...>_merged.json` demand√©.                              |
| `GET /evaluation/metrics`       | Lit `data/evaluation_metrics.json`.                                                                            |
| `POST /scraping/start`          | D√©clenche `meteo_scraper.py` puis `automate_pipeline.py --api-url ...` en t√¢che de fond (logs console).        |

> La base SQLite (via SQLAlchemy) stocke : `stations`, `bulletins`, `station_reports`. Les sch√©mas Pydantic (`app/schemas.py`) exposent `Tmin/Tmax` observ√©s/pr√©vus directement dans les r√©ponses.

---

## 5. Dashboard React

![Dashboard principal](assets/dashboard.png)
![Dashboard d√©taill√©](assets/dashboard2.png)
![Dashboard stations](assets/dashboad3.png)

### Pages principales

1. **Dashboard**
   - KPIs (bulletins, stations, MAE, accuracy).
   - Carte Leaflet des stations (clic ‚áí d√©tails).
   - Timeline des bulletins r√©cents.
   - Bloc informatif rappelant la commande `automate_pipeline.py`.

2. **Files**
   - Table (date, stations, chemin source).
   - Bouton ‚ÄúVoir‚Äù ‚á¢ ouvre une modale avec toutes les stations du bulletin (observations/pr√©visions) + metadata.

3. **Stations**
   - Liste filtrable, affiche `Tmin/Tmax` observ√©s & pr√©vus.
   - Acc√®s d√©taill√© (`/station/:id`) avec courbes temps, matrice de confusion, export CSV.

4. **√âvaluation**
   - KPIs globaux (MAE/RMSE, accuracy, F1 macro).
   - Carte heatmap, tendance MAE, matrice de confusion agr√©g√©e.

5. **Logs**
   - Liste des imports (via `/bulletins`), avec statut et mini-log.

6. **Param√®tres**
   - Langue par d√©faut (Fran√ßais) pour la g√©n√©ration de bulletins.
   - S√©lection du mod√®le LLM (`qwen3-vl:8b` par d√©faut).

### Build / D√©ploiement

```bash
cd frontend/frontend
npm run build
```

- G√©n√®re `frontend/frontend/build`. Servir via `serve -s build` ou derri√®re un reverse-proxy.
- V√©rifiez que `REACT_APP_API_URL` est d√©fini dans `.env` ou via la commande.

---

## 6. Scraping automatis√©

- Endpoint `POST /scraping/start` : lance `meteo_scraper.py` puis `automate_pipeline.py`. Les journaux apparaissent dans la console FastAPI.
- Pour un contr√¥le total, lancer manuellement sur le serveur :
  ```bash
  python meteo_scraper.py
  python automate_pipeline.py --api-url http://127.0.0.1:8000
  ```
- `automate_pipeline.py` :
  1. Ex√©cute les scripts de la pipeline (sauf ceux pass√©s avec `--skip-*`).
  2. Importe automatiquement chaque `*_merged.json` (avec `replace_existing` si `--force-reimport`).
  3. Journalise les fichiers import√©s dans `data/imported_files.log` (√©vite les doublons).

---

## 7. Nettoyage & agr√©gation

- `clean_merged_reports.py` : supprime les stations enti√®rement vides (`Tmin/Tmax` null des deux c√¥t√©s).
- `merge_all_merged.py` : produit `all_merged.json` (2024 + data/) avec `bulletin_count`, `generated_at`, `bulletins`.
- `evaluate_forecasts.py --output data/evaluation_metrics.json` : r√©sume les performances.

---

## 8. Donn√©es structur√©es

- `cities_positions.json` : coordonn√©es cliqu√©es √† la main (x,y absolus).
- `cities_rel.json` : coordonn√©es relatives (0-1) utilis√©es par les extracteurs.
- `cities_rel_with_coords.json` : version enrichie (lat/lon) pour la fusion.
- `2024_temps_qwen/` : JSON bruts par carte.
- `2024_temps_merged/` : JSON fusionn√©s par bulletin.
- `data/all_merged.json` : agr√©gation compl√®te (import√©e dans SQLite).
- `data/evaluation_metrics.json` : m√©triques globales pour la page √âvaluation.

---

## 9. FAQ / Tips

- **Je veux r√©initialiser la base** : supprimez `data/meteo.db` puis relancez `uvicorn` (le seed se refera depuis `data/all_merged.json`).
- **Je veux re-scraper depuis z√©ro** : supprimez `bulletins_pdf/` et `2024/`, puis relancez `meteo_scraper.py` + `automate_pipeline.py`.
- **Je veux comparer OCR vs LLM** : conservez `2024_temps_json_rel/` et `2024_temps_qwen/`, puis ajustez `merge_maps.py` pour fusionner l‚Äôune ou l‚Äôautre source.
- **D√©ploiement** :
  - API: `uvicorn app.main:app --host 0.0.0.0 --port 8000` derri√®re Nginx ou autre.
  - Front: `npm run build` puis `serve -s build` ou int√©gration dans un S3/CloudFront.
  - Assurez-vous que `REACT_APP_API_URL` pointe vers l‚ÄôURL publique de l‚ÄôAPI.

---

## 10. Licence & cr√©dits

- **Code Python** : MIT License (voir ci-dessous).
- **Libs principales** : `requests` (Apache 2.0), `beautifulsoup4` (MIT), `PyMuPDF` (AGPL v3), `Pillow` (PIL License), `opencv-python` (MIT), `numpy` (BSD), `pytesseract` (Apache 2.0), `FastAPI`/`Uvicorn` (MIT), `React` (MIT).
- **Donn√©es** : bulletins officiels `meteoburkina.bf`. V√©rifiez les droits de r√©utilisation avant diffusion.

---

Bon traitement des donn√©es m√©t√©o¬†! üåçüå§Ô∏è

---

## MIT License

```
Copyright (c) 2024 [Votre nom]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
